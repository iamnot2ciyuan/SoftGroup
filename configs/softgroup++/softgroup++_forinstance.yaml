model:
  channels: 32
  num_blocks: 6        # [关键修复] 从 7 改为 6，减少一层下采样，避免BatchNorm错误
  semantic_classes: 3   # 0=low_vegetation, 1=terrain, 2=tree
  instance_classes: 1   # 全部树归为1类实例
  sem2ins_classes: [2]  # 对语义类别2（tree）做实例分割
  semantic_only: False
  semantic_weight: [1.0, 1.0, 1.0]
  ignore_label: -100
  with_coords: True

  grouping_cfg:
    with_pyramid: False
    pyramid_base_size: 20
    with_octree: True
    score_thr: 0.2
    radius: 4          # [修复] 0.4米 -> 4个体素 (10cm体素 * 4 = 0.4米)
    mean_active: 2000  # [核心修复] 从50000降到2000，大幅减少内存需求
    class_numpoint_mean: [-1., -1., -1.]
    npoint_thr: 100    # 提高阈值，过滤小碎片
    ignore_classes: [0, 1]  # 只忽略low_vegetation和terrain，对tree(2)做聚类

  instance_voxel_cfg:
    scale: 10            # 10cm体素，更适合森林
    spatial_shape: 512

  train_cfg:
    lvl_fusion: True
    max_proposal_num: 1000
    pos_iou_thr: 0.5
    match_low_quality: True
    min_pos_thr: 0.3

  test_cfg:
    x4_split: False
    cls_score_thr: 0.05
    mask_score_thr: 0.5
    min_npoint: 50
    eval_tasks: ['semantic', 'instance']
  fixed_modules: []

data:
  train:
    type: 'forinstance'
    data_root: 'dataset/forinstance'
    prefix: 'train'
    suffix: '.las'
    training: True
    repeat: 4            # [修复] 降低Batch Size后，增加Repeat次数保证训练数据量
    voxel_cfg:
      scale: 10            # 10cm 体素，更适合森林
      spatial_shape: [512, 512, 512]  # [修复] 统一为3D，Z轴也需要足够空间
      max_npoint: 40000    # [修复] 降低最大点数以节省内存
      min_npoint: 2000     # [修复] 降低最小点数，减少空批次
  test:
    type: 'forinstance'
    data_root: 'dataset/forinstance'
    prefix: 'val'
    suffix: '.las'
    training: False
    voxel_cfg:
      scale: 10
      spatial_shape: [512, 512, 512]  # [修复] 统一为3D
      max_npoint: 60000
      min_npoint: 2000     # [修复] 降低最小点数

dataloader:
  train:
    batch_size: 1        # [修复] 降到最小，避免OOM
    num_workers: 2
  test:
    batch_size: 1
    num_workers: 1

optimizer:
  type: 'Adam'
  lr: 0.002

loss_weights:
  semantic_loss: 1.0
  offset_loss: 0.1
  cls_loss: 1.0
  mask_loss: 1.0
  iou_score_loss: 1.0

fp16: False
epochs: 108
step_epoch: 20
save_freq: 4
log_interval: 10
